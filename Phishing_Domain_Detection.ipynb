{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devpathak0212/Phishing-Domain-Detection/blob/main/Phishing_Domain_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WKyk4p2DVB0"
      },
      "source": [
        "# **Importing Required Libraries**\n",
        "\n",
        "The libraries imported are essential for data analysis, visualization, and machine learning. `pandas` is used for data manipulation and analysis, providing data structures like DataFrames. `numpy` is a powerful library for numerical computations, particularly with arrays. `matplotlib.pyplot` and `seaborn` are used for data visualization, with Seaborn built on top of Matplotlib to provide more aesthetically pleasing and complex visualizations. `sklearn.model_selection` contains functions like `train_test_split` for\n",
        "splitting datasets into training and testing sets. `sklearn.preprocessing` includes tools like `StandardScaler` for scaling features. `sklearn.metrics` offers functions for evaluating model performance, such as `classification_report` and `confusion_matrix`. Finally, `RandomForestClassifier` from `sklearn.ensemble` is an ensemble learning method used for classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PUZVPZBHg_u_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1iDkGxDC7Ty"
      },
      "source": [
        "# **Loading Dataset and Data Cleaning**\n",
        "\n",
        "In this part of the code, the dataset is loaded using `pandas` by reading a CSV file from the specified file path into a DataFrame called `data`. Basic information about the dataset, such as data types and statistical summaries, can be displayed using `data.info()` and `data.describe()`, though these lines are currently commented out. The dataset is printed to provide an overview of its contents. Additionally, a step to check for missing values in the dataset is implied, which would typically involve methods like `data.isnull().sum()` to identify any missing data points that need to be addressed for further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYsxQCzOC2ZM",
        "outputId": "2bece0a7-5be1-4755-a9bd-dfb19aee6a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
            "0                2               0                  0              0   \n",
            "1                4               0                  0              2   \n",
            "2                1               0                  0              1   \n",
            "3                2               0                  0              3   \n",
            "4                1               1                  0              4   \n",
            "...            ...             ...                ...            ...   \n",
            "58640            1               0                  0              5   \n",
            "58641            2               0                  0              0   \n",
            "58642            5               6                  3              6   \n",
            "58643            2               0                  0              0   \n",
            "58644            2               0                  0              3   \n",
            "\n",
            "       qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
            "0                         0              0           0            0   \n",
            "1                         0              0           0            0   \n",
            "2                         0              0           0            0   \n",
            "3                         0              0           0            0   \n",
            "4                         0              0           0            0   \n",
            "...                     ...            ...         ...          ...   \n",
            "58640                     0              1           0            0   \n",
            "58641                     0              0           0            0   \n",
            "58642                     0              2           1            1   \n",
            "58643                     0              0           0            0   \n",
            "58644                     0              0           0            0   \n",
            "\n",
            "       qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  \\\n",
            "0                        0              0  ...                1   \n",
            "1                        0              0  ...                1   \n",
            "2                        0              0  ...                1   \n",
            "3                        0              0  ...                1   \n",
            "4                        0              0  ...                1   \n",
            "...                    ...            ...  ...              ...   \n",
            "58640                    0              0  ...                1   \n",
            "58641                    0              0  ...                1   \n",
            "58642                    0              0  ...                1   \n",
            "58643                    0              0  ...                5   \n",
            "58644                    0              0  ...                1   \n",
            "\n",
            "       qty_nameservers  qty_mx_servers  ttl_hostname  tls_ssl_certificate  \\\n",
            "0                    4               2          3598                    0   \n",
            "1                    4               1          3977                    1   \n",
            "2                    2               1         10788                    0   \n",
            "3                    2               1         14339                    1   \n",
            "4                    2               1           389                    1   \n",
            "...                ...             ...           ...                  ...   \n",
            "58640                2               2           563                    0   \n",
            "58641                4               0           122                    1   \n",
            "58642                2               1          1122                    0   \n",
            "58643                2               5           299                    1   \n",
            "58644                2               1          3361                    1   \n",
            "\n",
            "       qty_redirects  url_google_index  domain_google_index  url_shortened  \\\n",
            "0                  0                 0                    0              0   \n",
            "1                  0                 0                    0              0   \n",
            "2                  0                 0                    0              0   \n",
            "3                  0                 0                    0              0   \n",
            "4                  1                 0                    0              0   \n",
            "...              ...               ...                  ...            ...   \n",
            "58640              0                 0                    0              0   \n",
            "58641              0                 0                    0              0   \n",
            "58642              0                 0                    0              0   \n",
            "58643              1                 0                    0              0   \n",
            "58644              0                 0                    0              0   \n",
            "\n",
            "       phishing  \n",
            "0             0  \n",
            "1             0  \n",
            "2             0  \n",
            "3             1  \n",
            "4             1  \n",
            "...         ...  \n",
            "58640         1  \n",
            "58641         0  \n",
            "58642         1  \n",
            "58643         0  \n",
            "58644         0  \n",
            "\n",
            "[58645 rows x 112 columns]\n",
            "qty_dot_url             0\n",
            "qty_hyphen_url          0\n",
            "qty_underline_url       0\n",
            "qty_slash_url           0\n",
            "qty_questionmark_url    0\n",
            "                       ..\n",
            "qty_redirects           0\n",
            "url_google_index        0\n",
            "domain_google_index     0\n",
            "url_shortened           0\n",
            "phishing                0\n",
            "Length: 112, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/dataset_small.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(data)\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsT4QyyDcrL"
      },
      "source": [
        "# **URL Feature Extraction**\n",
        "\n",
        "In this part of the code, specific URL-based features are identified and extracted from the dataset. These features, stored in the `url_features` list, include various counts and characteristics of URL components such as dots, hyphens, underscores, slashes, question marks, equal signs, and other special characters within the URLs. Additionally, features like URL length, presence in Google's index, and whether the URL is shortened are included. The statistical summary of these features is displayed using `data[url_features].describe()`, providing insights into their distribution and central tendencies within the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_kkqO-ugyn",
        "outputId": "f90f7532-cda0-4fde-eb1a-4b822723c4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
            "count  58645.000000    58645.000000       58645.000000   58645.000000   \n",
            "mean       2.284338        0.457123           0.171285       1.937522   \n",
            "std        1.473209        1.339340           0.801919       2.037525   \n",
            "min        1.000000        0.000000           0.000000       0.000000   \n",
            "25%        2.000000        0.000000           0.000000       0.000000   \n",
            "50%        2.000000        0.000000           0.000000       1.000000   \n",
            "75%        3.000000        0.000000           0.000000       3.000000   \n",
            "max       24.000000       35.000000          21.000000      44.000000   \n",
            "\n",
            "       qty_questionmark_url  qty_equal_url    qty_at_url   qty_and_url  \\\n",
            "count          58645.000000   58645.000000  58645.000000  58645.000000   \n",
            "mean               0.014102       0.311177      0.033456      0.212959   \n",
            "std                0.138156       1.159198      0.343272      1.130323   \n",
            "min                0.000000       0.000000      0.000000      0.000000   \n",
            "25%                0.000000       0.000000      0.000000      0.000000   \n",
            "50%                0.000000       0.000000      0.000000      0.000000   \n",
            "75%                0.000000       0.000000      0.000000      0.000000   \n",
            "max                9.000000      23.000000     43.000000     26.000000   \n",
            "\n",
            "       qty_exclamation_url  qty_space_url  ...  qty_comma_url  qty_plus_url  \\\n",
            "count         58645.000000   58645.000000  ...   58645.000000  58645.000000   \n",
            "mean              0.004451       0.001535  ...       0.003274      0.004212   \n",
            "std               0.107352       0.089320  ...       0.093381      0.136331   \n",
            "min               0.000000       0.000000  ...       0.000000      0.000000   \n",
            "25%               0.000000       0.000000  ...       0.000000      0.000000   \n",
            "50%               0.000000       0.000000  ...       0.000000      0.000000   \n",
            "75%               0.000000       0.000000  ...       0.000000      0.000000   \n",
            "max              10.000000       9.000000  ...      11.000000     19.000000   \n",
            "\n",
            "       qty_asterisk_url  qty_hashtag_url  qty_dollar_url  qty_percent_url  \\\n",
            "count      58645.000000     58645.000000    58645.000000     58645.000000   \n",
            "mean           0.006855         0.000767        0.002865         0.162503   \n",
            "std            0.370849         0.075802        0.122604         2.115804   \n",
            "min            0.000000         0.000000        0.000000         0.000000   \n",
            "25%            0.000000         0.000000        0.000000         0.000000   \n",
            "50%            0.000000         0.000000        0.000000         0.000000   \n",
            "75%            0.000000         0.000000        0.000000         0.000000   \n",
            "max           60.000000        13.000000       10.000000       174.000000   \n",
            "\n",
            "        qty_tld_url    length_url  url_google_index  url_shortened  \n",
            "count  58645.000000  58645.000000      58645.000000   58645.000000  \n",
            "mean       1.068429     44.959297          0.001279       0.008287  \n",
            "std        0.305755     54.712657          0.037599       0.090657  \n",
            "min        0.000000      4.000000         -1.000000       0.000000  \n",
            "25%        1.000000     18.000000          0.000000       0.000000  \n",
            "50%        1.000000     29.000000          0.000000       0.000000  \n",
            "75%        1.000000     52.000000          0.000000       0.000000  \n",
            "max       12.000000   4165.000000          1.000000       1.000000  \n",
            "\n",
            "[8 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "url_features = ['qty_dot_url', 'qty_hyphen_url', 'qty_underline_url', 'qty_slash_url',\n",
        "                'qty_questionmark_url', 'qty_equal_url', 'qty_at_url', 'qty_and_url',\n",
        "                'qty_exclamation_url', 'qty_space_url', 'qty_tilde_url', 'qty_comma_url',\n",
        "                'qty_plus_url', 'qty_asterisk_url', 'qty_hashtag_url', 'qty_dollar_url',\n",
        "                'qty_percent_url', 'qty_tld_url', 'length_url', 'url_google_index', 'url_shortened']\n",
        "\n",
        "# Analyze the URL-based features\n",
        "print(data[url_features].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74uspNZoDt0T"
      },
      "source": [
        "# **Domain Feature Extraction**\n",
        "\n",
        "In this part of the code, domain-based features are extracted from the dataset and analyzed. The `domain_features` list includes counts of various characters and elements within the domain, such as dots, hyphens, underscores, slashes, and other special characters, as well as the number of vowels in the domain. Additional features include domain length, whether the domain is an IP address, server-client domain information, SPF records, domain activation and expiration times, and whether the domain is indexed by Google. The statistical summary of these domain features is displayed using `data[domain_features].describe()`, offering a comprehensive overview of their distribution and key statistics within the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCcAiW9curFJ",
        "outputId": "edc1d30e-7dee-4b7b-d258-83f0518330ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       qty_dot_domain  qty_hyphen_domain  qty_underline_domain  \\\n",
            "count    58645.000000       58645.000000          58645.000000   \n",
            "mean         1.799540           0.133294              0.000290   \n",
            "std          0.790989           0.465673              0.019802   \n",
            "min          0.000000           0.000000              0.000000   \n",
            "25%          1.000000           0.000000              0.000000   \n",
            "50%          2.000000           0.000000              0.000000   \n",
            "75%          2.000000           0.000000              0.000000   \n",
            "max         21.000000          11.000000              2.000000   \n",
            "\n",
            "       qty_slash_domain  qty_questionmark_domain  qty_equal_domain  \\\n",
            "count           58645.0                  58645.0           58645.0   \n",
            "mean                0.0                      0.0               0.0   \n",
            "std                 0.0                      0.0               0.0   \n",
            "min                 0.0                      0.0               0.0   \n",
            "25%                 0.0                      0.0               0.0   \n",
            "50%                 0.0                      0.0               0.0   \n",
            "75%                 0.0                      0.0               0.0   \n",
            "max                 0.0                      0.0               0.0   \n",
            "\n",
            "       qty_at_domain  qty_and_domain  qty_exclamation_domain  \\\n",
            "count   58645.000000         58645.0                 58645.0   \n",
            "mean        0.000017             0.0                     0.0   \n",
            "std         0.004129             0.0                     0.0   \n",
            "min         0.000000             0.0                     0.0   \n",
            "25%         0.000000             0.0                     0.0   \n",
            "50%         0.000000             0.0                     0.0   \n",
            "75%         0.000000             0.0                     0.0   \n",
            "max         1.000000             0.0                     0.0   \n",
            "\n",
            "       qty_space_domain  ...  qty_dollar_domain  qty_percent_domain  \\\n",
            "count           58645.0  ...            58645.0             58645.0   \n",
            "mean                0.0  ...                0.0                 0.0   \n",
            "std                 0.0  ...                0.0                 0.0   \n",
            "min                 0.0  ...                0.0                 0.0   \n",
            "25%                 0.0  ...                0.0                 0.0   \n",
            "50%                 0.0  ...                0.0                 0.0   \n",
            "75%                 0.0  ...                0.0                 0.0   \n",
            "max                 0.0  ...                0.0                 0.0   \n",
            "\n",
            "       qty_vowels_domain  domain_length  domain_in_ip  server_client_domain  \\\n",
            "count       58645.000000   58645.000000  58645.000000          58645.000000   \n",
            "mean            5.440992      18.073016      0.003427              0.003530   \n",
            "std             2.714293       7.244541      0.058444              0.059307   \n",
            "min             0.000000       4.000000      0.000000              0.000000   \n",
            "25%             4.000000      14.000000      0.000000              0.000000   \n",
            "50%             5.000000      17.000000      0.000000              0.000000   \n",
            "75%             7.000000      21.000000      0.000000              0.000000   \n",
            "max            61.000000     231.000000      1.000000              1.000000   \n",
            "\n",
            "         domain_spf  time_domain_activation  time_domain_expiration  \\\n",
            "count  58645.000000            58645.000000            58645.000000   \n",
            "mean      -0.030147             2531.939483              293.615074   \n",
            "std        0.591021             2799.792419              562.400108   \n",
            "min       -1.000000               -1.000000               -1.000000   \n",
            "25%        0.000000               -1.000000               -1.000000   \n",
            "50%        0.000000             1488.000000              125.000000   \n",
            "75%        0.000000             4754.000000              319.000000   \n",
            "max        1.000000            17775.000000            22574.000000   \n",
            "\n",
            "       domain_google_index  \n",
            "count         58645.000000  \n",
            "mean              0.002234  \n",
            "std               0.047927  \n",
            "min              -1.000000  \n",
            "25%               0.000000  \n",
            "50%               0.000000  \n",
            "75%               0.000000  \n",
            "max               1.000000  \n",
            "\n",
            "[8 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "domain_features = ['qty_dot_domain', 'qty_hyphen_domain', 'qty_underline_domain', 'qty_slash_domain',\n",
        "                   'qty_questionmark_domain', 'qty_equal_domain', 'qty_at_domain', 'qty_and_domain',\n",
        "                   'qty_exclamation_domain', 'qty_space_domain', 'qty_tilde_domain', 'qty_comma_domain',\n",
        "                   'qty_plus_domain', 'qty_asterisk_domain', 'qty_hashtag_domain', 'qty_dollar_domain',\n",
        "                   'qty_percent_domain', 'qty_vowels_domain', 'domain_length', 'domain_in_ip',\n",
        "                   'server_client_domain', 'domain_spf', 'time_domain_activation', 'time_domain_expiration',\n",
        "                   'domain_google_index']\n",
        "# Analyze the Domain-based features\n",
        "print(data[domain_features].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTF-4asoDyZs"
      },
      "source": [
        "# **Page Feature Extraction**\n",
        "\n",
        "In this part of the code, page-based features are extracted from the dataset for analysis. The `page_features` list includes counts of various characters within the page parameters, such as dots, hyphens, underscores, slashes, and other special characters, as well as the length of the parameters, presence of the top-level domain (TLD) in the parameters, and the total number of parameters. By printing the statistical summary using `data[page_features].describe()`, the code provides insights into the distribution and key statistics of these page-specific features within the dataset, helping to understand their characteristics and potential impact on the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPGIgrYO9__4",
        "outputId": "e0447b78-3f58-485e-9075-4e8daab4614a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       qty_dot_params  qty_hyphen_params  qty_underline_params  \\\n",
            "count    58645.000000       58645.000000          58645.000000   \n",
            "mean        -0.714451          -0.816506             -0.791781   \n",
            "std          1.193137           0.771199              0.797698   \n",
            "min         -1.000000          -1.000000             -1.000000   \n",
            "25%         -1.000000          -1.000000             -1.000000   \n",
            "50%         -1.000000          -1.000000             -1.000000   \n",
            "75%         -1.000000          -1.000000             -1.000000   \n",
            "max         23.000000          35.000000             21.000000   \n",
            "\n",
            "       qty_slash_params  qty_questionmark_params  qty_equal_params  \\\n",
            "count      58645.000000             58645.000000      58645.000000   \n",
            "mean          -0.830898                -0.860670         -0.587723   \n",
            "std            0.663899                 0.386856          1.345035   \n",
            "min           -1.000000                -1.000000         -1.000000   \n",
            "25%           -1.000000                -1.000000         -1.000000   \n",
            "50%           -1.000000                -1.000000         -1.000000   \n",
            "75%           -1.000000                -1.000000         -1.000000   \n",
            "max           43.000000                 9.000000         23.000000   \n",
            "\n",
            "       qty_at_params  qty_and_params  qty_exclamation_params  \\\n",
            "count   58645.000000    58645.000000            58645.000000   \n",
            "mean       -0.846193       -0.680791               -0.872692   \n",
            "std         0.432952        1.235146                0.339404   \n",
            "min        -1.000000       -1.000000               -1.000000   \n",
            "25%        -1.000000       -1.000000               -1.000000   \n",
            "50%        -1.000000       -1.000000               -1.000000   \n",
            "75%        -1.000000       -1.000000               -1.000000   \n",
            "max        10.000000       22.000000               10.000000   \n",
            "\n",
            "       qty_space_params  qty_tilde_params  qty_comma_params  qty_plus_params  \\\n",
            "count      58645.000000      58645.000000      58645.000000     58645.000000   \n",
            "mean          -0.873323         -0.873357         -0.871242        -0.870969   \n",
            "std            0.333280          0.332832          0.347086         0.347966   \n",
            "min           -1.000000         -1.000000         -1.000000        -1.000000   \n",
            "25%           -1.000000         -1.000000         -1.000000        -1.000000   \n",
            "50%           -1.000000         -1.000000         -1.000000        -1.000000   \n",
            "75%           -1.000000         -1.000000         -1.000000        -1.000000   \n",
            "max            4.000000          1.000000         11.000000         6.000000   \n",
            "\n",
            "       qty_asterisk_params  qty_hashtag_params  qty_dollar_params  \\\n",
            "count         58645.000000        58645.000000       58645.000000   \n",
            "mean             -0.873305           -0.873442          -0.872862   \n",
            "std               0.333350            0.332480           0.336390   \n",
            "min              -1.000000           -1.000000          -1.000000   \n",
            "25%              -1.000000           -1.000000          -1.000000   \n",
            "50%              -1.000000           -1.000000          -1.000000   \n",
            "75%              -1.000000           -1.000000          -1.000000   \n",
            "max               4.000000            0.000000           4.000000   \n",
            "\n",
            "       qty_percent_params  params_length  tld_present_params    qty_params  \n",
            "count        58645.000000   58645.000000        58645.000000  58645.000000  \n",
            "mean            -0.791559       8.482462           -0.836354     -0.636832  \n",
            "std              1.285886      42.598270            0.459396      1.137735  \n",
            "min             -1.000000      -1.000000           -1.000000     -1.000000  \n",
            "25%             -1.000000      -1.000000           -1.000000     -1.000000  \n",
            "50%             -1.000000      -1.000000           -1.000000     -1.000000  \n",
            "75%             -1.000000      -1.000000           -1.000000     -1.000000  \n",
            "max             65.000000    4094.000000            1.000000     23.000000  \n"
          ]
        }
      ],
      "source": [
        "page_features = ['qty_dot_params', 'qty_hyphen_params', 'qty_underline_params', 'qty_slash_params',\n",
        "                 'qty_questionmark_params', 'qty_equal_params', 'qty_at_params', 'qty_and_params',\n",
        "                 'qty_exclamation_params', 'qty_space_params', 'qty_tilde_params', 'qty_comma_params',\n",
        "                 'qty_plus_params', 'qty_asterisk_params', 'qty_hashtag_params', 'qty_dollar_params',\n",
        "                 'qty_percent_params', 'params_length', 'tld_present_params', 'qty_params']\n",
        "# Analyze the Page-based features\n",
        "print(data[page_features].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmEvY_6rD7FK"
      },
      "source": [
        "# **Content Feature Extraction**\n",
        "\n",
        "In this part of the code, content-based features are extracted from the dataset for analysis. The `content_features` list includes counts of various characters within the content, such as dots, hyphens, underscores, slashes, and other special characters, along with the length of the content. By printing the statistical summary using `data[content_features].describe()`, the code provides insights into the distribution and key statistics of these content-specific features within the dataset, helping to understand their characteristics and how they might influence further analysis or model building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05HR_aGZ_WEI",
        "outputId": "9c104a5b-67cc-4098-c701-df3a0861a756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       qty_dot_file  qty_hyphen_file  qty_underline_file  qty_slash_file  \\\n",
            "count  58645.000000     58645.000000        58645.000000    58645.000000   \n",
            "mean      -0.045750        -0.211084           -0.260466       -0.298525   \n",
            "std        0.762056         0.870709            0.606537        0.457615   \n",
            "min       -1.000000        -1.000000           -1.000000       -1.000000   \n",
            "25%       -1.000000        -1.000000           -1.000000       -1.000000   \n",
            "50%        0.000000         0.000000            0.000000        0.000000   \n",
            "75%        0.000000         0.000000            0.000000        0.000000   \n",
            "max       12.000000        21.000000           17.000000        0.000000   \n",
            "\n",
            "       qty_questionmark_file  qty_equal_file   qty_at_file  qty_and_file  \\\n",
            "count           58645.000000    58645.000000  58645.000000  58645.000000   \n",
            "mean               -0.298525       -0.296035     -0.298082     -0.296377   \n",
            "std                 0.457615        0.463333      0.458425      0.461529   \n",
            "min                -1.000000       -1.000000     -1.000000     -1.000000   \n",
            "25%                -1.000000       -1.000000     -1.000000     -1.000000   \n",
            "50%                 0.000000        0.000000      0.000000      0.000000   \n",
            "75%                 0.000000        0.000000      0.000000      0.000000   \n",
            "max                 0.000000        3.000000      2.000000      3.000000   \n",
            "\n",
            "       qty_exclamation_file  qty_space_file  qty_tilde_file  qty_comma_file  \\\n",
            "count          58645.000000    58645.000000    58645.000000    58645.000000   \n",
            "mean              -0.296956       -0.297877       -0.298082       -0.297672   \n",
            "std                0.460601        0.461782        0.458945        0.460731   \n",
            "min               -1.000000       -1.000000       -1.000000       -1.000000   \n",
            "25%               -1.000000       -1.000000       -1.000000       -1.000000   \n",
            "50%                0.000000        0.000000        0.000000        0.000000   \n",
            "75%                0.000000        0.000000        0.000000        0.000000   \n",
            "max                4.000000        9.000000        4.000000        5.000000   \n",
            "\n",
            "       qty_plus_file  qty_asterisk_file  qty_hashtag_file  qty_dollar_file  \\\n",
            "count   58645.000000       58645.000000      58645.000000     58645.000000   \n",
            "mean       -0.297366          -0.296752         -0.298525        -0.298525   \n",
            "std         0.468779           0.531246          0.457615         0.457615   \n",
            "min        -1.000000          -1.000000         -1.000000        -1.000000   \n",
            "25%        -1.000000          -1.000000         -1.000000        -1.000000   \n",
            "50%         0.000000           0.000000          0.000000         0.000000   \n",
            "75%         0.000000           0.000000          0.000000         0.000000   \n",
            "max        19.000000          60.000000          0.000000         0.000000   \n",
            "\n",
            "       qty_percent_file   file_length  \n",
            "count      58645.000000  58645.000000  \n",
            "mean          -0.242305      4.659067  \n",
            "std            1.713954     16.358671  \n",
            "min           -1.000000     -1.000000  \n",
            "25%           -1.000000     -1.000000  \n",
            "50%            0.000000      0.000000  \n",
            "75%            0.000000      9.000000  \n",
            "max          174.000000   1232.000000  \n"
          ]
        }
      ],
      "source": [
        "content_features = ['qty_dot_file', 'qty_hyphen_file', 'qty_underline_file', 'qty_slash_file',\n",
        "                    'qty_questionmark_file', 'qty_equal_file', 'qty_at_file', 'qty_and_file',\n",
        "                    'qty_exclamation_file', 'qty_space_file', 'qty_tilde_file', 'qty_comma_file',\n",
        "                    'qty_plus_file', 'qty_asterisk_file', 'qty_hashtag_file', 'qty_dollar_file',\n",
        "                    'qty_percent_file', 'file_length']\n",
        "# Analyze the Content-based features\n",
        "print(data[content_features].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjnKb09xEAcn"
      },
      "source": [
        "# **Feature Selection**\n",
        "\n",
        "In this step, the code combines all the previously defined feature sets into a single list called `all_features`, which includes URL-based, domain-based, page-based, and content-based features. This comprehensive list can be used for further analysis or modeling. Additionally, there are commented-out lines that allow selecting only specific feature sets (URL, domain, page, or content) if needed, enabling flexibility in choosing the features according to specific requirements or analysis goals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6fDCkIDv-oC"
      },
      "outputs": [],
      "source": [
        "# Combine all feature sets\n",
        "all_features = url_features + domain_features + page_features + content_features\n",
        "# all_features = url_features\n",
        "# all_features = domain_features\n",
        "# all_features = page_features\n",
        "# all_features = content_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ieq78_TEWQZ"
      },
      "source": [
        "# **Splitting the Train-Test Data and Data Standardization**\n",
        "\n",
        "In this step, the dataset is split into training and testing sets using the selected features (`all_features`) and the target variable (`phishing`). The `train_test_split` function from `sklearn.model_selection` is used to allocate 70% of the data for training and 30% for testing, with a fixed random state for reproducibility. After splitting, the features in both the training and testing sets are standardized using `StandardScaler` from `sklearn.preprocessing`, ensuring that the data has a mean of 0 and a standard deviation of 1. This standardization step is crucial for improving the performance and convergence of many machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG6SWunaEOA-"
      },
      "outputs": [],
      "source": [
        "X = data[all_features]\n",
        "y = data['phishing']\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the feature set\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X38CIsBZE0qi"
      },
      "source": [
        "# **Preparing Model**\n",
        "\n",
        "In this segment of the code, a dictionary named `models` is initialized to hold different machine learning models. Currently, only the `RandomForestClassifier` from `sklearn.ensemble` is selected and active for use. Other models, such as `LogisticRegression`, `SVC` (Support Vector Machine), and `KNeighborsClassifier`, are included in the dictionary but commented out, indicating they are potential alternatives that can be activated and evaluated based on their performance results. This setup allows for easy experimentation and comparison of different models for the task at hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPMdTQ5DEu5H"
      },
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77H77CFQFCZa"
      },
      "source": [
        "# **Testing and Evaluating the Model**\n",
        "\n",
        "In this segment of the code, the selected machine learning model(s) from the `models` dictionary are trained and evaluated. For each model, the `fit` method is used to train the model on the training data (`X_train` and `y_train`). Predictions are then made on the test data (`X_test`) using the `predict` method. The performance of each model is evaluated by printing a classification report, which includes metrics such as precision, recall, and F1-score, and a confusion matrix, which provides a detailed breakdown of the model's performance on the test data. This process allows for a comprehensive assessment of the model's accuracy and effectiveness in classifying the target variable (`phishing`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoomuNowE6DO",
        "outputId": "82a799eb-79ee-4862-d75c-82e7dee6e32d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94      8428\n",
            "           1       0.94      0.95      0.94      9166\n",
            "\n",
            "    accuracy                           0.94     17594\n",
            "   macro avg       0.94      0.94      0.94     17594\n",
            "weighted avg       0.94      0.94      0.94     17594\n",
            "\n",
            "Confusion Matrix: \n",
            "[[7840  588]\n",
            " [ 496 8670]]\n",
            "K-Nearest Neighbors Model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91      8428\n",
            "           1       0.93      0.91      0.92      9166\n",
            "\n",
            "    accuracy                           0.92     17594\n",
            "   macro avg       0.92      0.92      0.92     17594\n",
            "weighted avg       0.92      0.92      0.92     17594\n",
            "\n",
            "Confusion Matrix: \n",
            "[[7776  652]\n",
            " [ 816 8350]]\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{name} Model\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('Confusion Matrix: ')\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}